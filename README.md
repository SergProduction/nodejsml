# Мотивация
Удобная интерактивная разработка своих алгоритмов для больших данных.  
с возможностью загружать данные выборки в модель,  
сохранять вычисленную модель данных,  
и загружать ее снова при следующих сеансах работы

# как работать
1. Напишите свой алгоритм в папке `src/models/*`,  
унаследдовавшись от класса `./src/model.ts Model`  
2. Напишите реализацию работы с конкретным типом данных выборок  
в папке `./src/features/*`
3. Добавьте експорт вашей модель в `./src/features/index.ts`
4. Заходите в репл, и работайте! все готово.  
`npm run repl` - откроется интерактивнаыя консоль, где будет ваша модель,  
выполните (название вашей модели) `myModel.loadSample("название-выборки")`,  
данные выборки загрузятся в вашу модель,  
сделайте вычисление, тренировку весов модели,  
посмотрите результат,  
сохраните новые вычисленные значени `myModel.saveModel("название-модели")`,  
можно закрывать репл,  
потом можно заного зайти в репл и выполнить `myModel.loadModel("название-модели")` 


# Model
У модели есть свое внутренее впредставление данных, (modelData)
оно нужно чтоб хранить данные в таком виде, чтоб можно было производительно  
делать вычисления с этими данными,  
так же необходимо реализовать два метода `encode, decode`  
это сериализатор и десериализатор данных модели в примитивы js  
они нужны чтоб сохранять вычисленную (натренированную) модель данных в бд,  
напрямую с бд работать не надо.  

У модели есть реализованные методы `saveModel, loadModel`  
унаследовавшись от класса Model, ваш класс будет иметь эти методы  
`saveModel("название-модели")` - будет вызывать ваш метод encode,  
чтоб получить модель данных как примитив js,
и сохранит в файл ./data/models/"название-модели".json.
В след раз можно будет вопрользоватся методом
`loadModel("название-модели")` - который выгрузить данные из бд,  
и вызовет ваш decode(IOModelData) 

# Sample
Вам нужно будет брать откуда-то выборку для заполнения вашей модели сырыми данными,  
для этого есть интерфейс Sample<RowData>  
вы должны уналедоватся от него и реализовать метод loadSample("название-выборки")
выборки должны лежать в ./data/samples/*  
они могут быть в любом формате, с любой структурой данных,  
поэтому вы сами должны реализовать способ открытыя файла, чтения, получения данных, преобразования, и загрузку в модель.



# repl
`npm run repl`
для интерактивной работы с моделями


`
tf.load('')
`

# Model TF
term frequency

## терминалогия
__документ__  
строка, она распарсится на массив термов,  
и посчитается частота каждого терма

__корпус__  
массив документов, частота термов для всех документов.
Например - есть 5 документов, в одном 2 раза встречается слово "чашка",  
еще в одном 1 раз встечается слово "чашка", в остальных документах отсутствует,  
значит сырая частота слова чашка для корпуса будет - 3.
Корпус содержит словарь всех слов всех документов

__терм__  
слово, токен


## Методы

### Lib Counter
__target: Record<string, number>__  
считает кол-во одинаковых строк в массиве


### Model TF  

__docs: Counter[]__  
__corpus: Counter__  

считает сырую частоту слов для каждого документа this.docs  
и для корпуса по всем документам this.corpus  

- __addCorpus(corpus: string[])__  
добавить сразу весь корпус с документами  

- __addDoc(doc: string)__  
добавить один документ к корпусу  
можно вызывать несколько раз, дополнит существующий корпус новыми доментами

- __calcWeigths(handleCalcDoc?: CalcWeigthDoc, handleCalcCorpus?: CalcWeigthCorpus, isImmutable?: boolean)__  
пересчитывает частоту для каждого документа и для корпуса,  
по дефолту перезаписывает частоту в this.docs, this.corpus,  
если передать isImmutable = true, то вернет новый TF с перерасчитаными весами.  
handleCalcDoc, handleCalcCorpus - ф-ции для расчета весов термов для документта и для корпуса  
по умолчанию считает сырую частоту  


### GroupTF
__state: Record<string, TF>__  

создает много матриц TF

- __addCorpus(label: string, corpus: string[])__  
добавить\создать TF для label  
можно вызывать несколько раз, дополнит существующий корпус новыми доментами


- __calcWeigths__  
работает так же как TF.calcWeigths, применяется для каждого TF

- __predictLabel(doc: string)__  
определит на какой label TF больше всего похож новый документ

## Рекомендации

с помощью изменения функции расчета частот можно реализовать матрицу TF-IDF

[TF-IDF WIKI](https://ru.wikipedia.org/wiki/TF-IDF)  
[TF-IDF с примерами](http://nlpx.net/archives/57)

так же надо будет добавить кластеризацию  
и возможно косисную меру близости  

[кластеризация векторов](https://habr.com/ru/post/67078/)

каждый документ можно преобразовать в вектор  
размерностью с словарь всех слов (корпус)  
для этого надо преобразовать корпус в упорядоченый массив слов  
промапать документ по всем термам корпуса,  
проставить 0 там где слово из документа не встречается в корпусе  
там где встречается, поставить весь слова из документа  


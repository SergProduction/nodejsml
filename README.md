# Model
модель это класс унаследованный от src/models/base,  
можно создавать свои модели  
создайте класс в директори src/models/*  
новая модель должна иметь слудующие методы  

__type RowData__  
сырые данные которые модель принимает в качестве обучающий выборки

__type ModelData__  
наренированная модель весов

__decode(modelData: ModelData): void__  
загрузка примитивных данных в внутреннее представение данных модели
нужно чтоб загружать натренированные веса из файла в модель  

__encode(): ModelData__  
выгрузка внутренних представлений данных модели в примитив js  
нужно чтоб сохронять натренированные веса в файл  

__setSample(rowData: RowData): void__  
нужно чтоб загружать выборку из json в модель

__learn(activateFn: any): any__  
вызывается для тренировки модели, вычисления новых весов,  
можно передать функцию вычисления весов  
(рекомендация) - для дебага удобно возвращать новую модель с новыми весами

__predict(p: any): any__  
вызывается для проверки модели  


Так же base-model имеет уже реализованные методы 

__async load(sampleName: string, modelName: string): void__  
при первой загрузки модели (model.load),  
модель вычислит (model.setSample) веса на основе выборки  
после вычисления сохранит веса в файл (model.encode),  
при последующих загрузках (model.load),  
ранее вычисленные веса загрузятся (model.decode) из файла.  

__async save(modelName: string): void__  
можно перезаписать веса,  
для этого надо передать модель с новыми весами в метод model.save  


# repl
`npm run repl`
для интерактивной работы с моделями


`
tf.load('')
`

# Model TF
term frequency

## терминалогия
__документ__  
строка, она распарсится на массив термов,  
и посчитается частота каждого терма

__корпус__  
массив документов, частота термов для всех документов.
Например - есть 5 документов, в одном 2 раза встречается слово "чашка",  
еще в одном 1 раз встечается слово "чашка", в остальных документах отсутствует,  
значит сырая частота слова чашка для корпуса будет - 3.
Корпус содержит словарь всех слов всех документов

__терм__  
слово, токен


## Методы

### Lib Counter
__target: Record<string, number>__  
считает кол-во одинаковых строк в массиве


### Model TF  

__docs: Counter[]__  
__corpus: Counter__  

считает сырую частоту слов для каждого документа this.docs  
и для корпуса по всем документам this.corpus  

- __addCorpus(corpus: string[])__  
добавить сразу весь корпус с документами  

- __addDoc(doc: string)__  
добавить один документ к корпусу  
можно вызывать несколько раз, дополнит существующий корпус новыми доментами

- __calcWeigths(handleCalcDoc?: CalcWeigthDoc, handleCalcCorpus?: CalcWeigthCorpus, isImmutable?: boolean)__  
пересчитывает частоту для каждого документа и для корпуса,  
по дефолту перезаписывает частоту в this.docs, this.corpus,  
если передать isImmutable = true, то вернет новый TF с перерасчитаными весами.  
handleCalcDoc, handleCalcCorpus - ф-ции для расчета весов термов для документта и для корпуса  
по умолчанию считает сырую частоту  


### GroupTF
__state: Record<string, TF>__  

создает много матриц TF

- __addCorpus(label: string, corpus: string[])__  
добавить\создать TF для label  
можно вызывать несколько раз, дополнит существующий корпус новыми доментами


- __calcWeigths__  
работает так же как TF.calcWeigths, применяется для каждого TF

- __predictLabel(doc: string)__  
определит на какой label TF больше всего похож новый документ

## Рекомендации

с помощью изменения функции расчета частот можно реализовать матрицу TF-IDF

[TF-IDF WIKI](https://ru.wikipedia.org/wiki/TF-IDF)  
[TF-IDF с примерами](http://nlpx.net/archives/57)

так же надо будет добавить кластеризацию  
и возможно косисную меру близости  

[кластеризация векторов](https://habr.com/ru/post/67078/)

каждый документ можно преобразовать в вектор  
размерностью с словарь всех слов (корпус)  
для этого надо преобразовать корпус в упорядоченый массив слов  
промапать документ по всем термам корпуса,  
проставить 0 там где слово из документа не встречается в корпусе  
там где встречается, поставить весь слова из документа  


# TF
term frequency

## терминалогия
__документ__  
строка, она распарсится на массив термов,  
и посчитается частота каждого терма

__корпус__  
массив документов, частота термов для всех документов.
Например - есть 5 документов, в одном 2 раза встречается слово "чашка",  
еще в одном 1 раз встечается слово "чашка", в остальных документах отсутствует,  
значит сырая частота слова чашка для корпуса будет - 3.
Корпус содержит словарь всех слов всех документов

__терм__  
слово, токен


## Методы

## class Counter
target: Record<string, number>  
считает кол-во одинаковых строк в массиве


## class TF  
docs: Counter[]  
corpus: Counter  
счиатет сырую частоту слов для каждого документа this.docs  
и для корпуса по всем документам this.corpus  

`addCorpus(corpus: string[])`  
добавить сразу весь корпус с документами  

`addDoc(doc: string)`  
добавить один документ к корпусу  
можно вызывать несколько раз, дополнит существующий корпус новыми доментами

`calcWeigths(handleCalcDoc?: CalcWeigthDoc, handleCalcCorpus?: CalcWeigthCorpus, isImmutable?: boolean)`  
пересчитывает частоту для каждого документа и для корпуса,  
по дефолту перезаписывает частоту в this.docs, this.corpus,  
если передать isImmutable = true, то вернет новый TF с перерасчитаными весами.  
handleCalcDoc, handleCalcCorpus - ф-ции для расчета весов термов для документта и для корпуса  
по умолчанию считает сырую частоту  


## class ManyTF
state: Record<string, TF>  
создает много матриц TF

`addCorpus(label: string, corpus: string[])`  
добавить\создать TF для label  
можно вызывать несколько раз, дополнит существующий корпус новыми доментами


`calcWeigths`
работает так же как TF.calcWeigths, применяется для каждого TF

`predictLabel(doc: string)`
определит на какой label TF больше всего похож новый документ

## Рекомендации

с помощью изменения функции расчета частот можно реализовать матрицу TF-IDF

[TF-IDF WIKI](https://ru.wikipedia.org/wiki/TF-IDF)  
[TF-IDF с примерами](http://nlpx.net/archives/57)

так же надо будет добавить кластеризацию  
и возможно косисную меру близости  

[кластеризация векторов](https://habr.com/ru/post/67078/)

каждый документ можно преобразовать в вектор  
размерностью с словарь всех слов (корпус)  
для этого надо преобразовать корпус в упорядоченый массив слов  
промапать документ по всем термам корпуса,  
проставить 0 там где слово из документа не встречается в корпусе  
там где встречается, поставить весь слова из документа  


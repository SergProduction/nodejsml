# TF
term frequency

## терминалогия
__документ__  
строка, она распарсится на массив термов,  
и посчитается частота каждого терма

__корпус__  
массив документов, частота термов для всех документов.
Например - есть 5 документов, в одном 2 раза встречается слово "чашка",  
еще в одном 1 раз встечается слово "чашка", в остальных документах отсутствует,  
значит сырая частота слова чашка для корпуса будет - 3.
Корпус содержит словарь всех слов всех документов

__терм__  
слово, токен


## Методы

### Counter
__target: Record<string, number>__  
считает кол-во одинаковых строк в массиве


### TF  

__docs: Counter[]__  
__corpus: Counter__  

счиатет сырую частоту слов для каждого документа this.docs  
и для корпуса по всем документам this.corpus  

- __addCorpus(corpus: string[])__  
добавить сразу весь корпус с документами  

- __addDoc(doc: string)__  
добавить один документ к корпусу  
можно вызывать несколько раз, дополнит существующий корпус новыми доментами

- __calcWeigths(handleCalcDoc?: CalcWeigthDoc, handleCalcCorpus?: CalcWeigthCorpus, isImmutable?: boolean)__  
пересчитывает частоту для каждого документа и для корпуса,  
по дефолту перезаписывает частоту в this.docs, this.corpus,  
если передать isImmutable = true, то вернет новый TF с перерасчитаными весами.  
handleCalcDoc, handleCalcCorpus - ф-ции для расчета весов термов для документта и для корпуса  
по умолчанию считает сырую частоту  


### ManyTF
__state: Record<string, TF>__  
создает много матриц TF

- __addCorpus(label: string, corpus: string[])__  
добавить\создать TF для label  
можно вызывать несколько раз, дополнит существующий корпус новыми доментами


- __calcWeigths__
работает так же как TF.calcWeigths, применяется для каждого TF

- __predictLabel(doc: string)__
определит на какой label TF больше всего похож новый документ

## Рекомендации

с помощью изменения функции расчета частот можно реализовать матрицу TF-IDF

[TF-IDF WIKI](https://ru.wikipedia.org/wiki/TF-IDF)  
[TF-IDF с примерами](http://nlpx.net/archives/57)

так же надо будет добавить кластеризацию  
и возможно косисную меру близости  

[кластеризация векторов](https://habr.com/ru/post/67078/)

каждый документ можно преобразовать в вектор  
размерностью с словарь всех слов (корпус)  
для этого надо преобразовать корпус в упорядоченый массив слов  
промапать документ по всем термам корпуса,  
проставить 0 там где слово из документа не встречается в корпусе  
там где встречается, поставить весь слова из документа  

